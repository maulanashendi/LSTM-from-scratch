{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import lightning as L\n",
    "from LSTM import LSTMbyHand\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin: Observed = 68526.1016, Predicted = tensor(-0.2471, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qy/94yjrytd2xld3rt1bgznnqs00000gn/T/ipykernel_9743/1790551668.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_value = torch.tensor(input, dtype=torch.float32).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "model = LSTMbyHand()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df = pd.read_csv('/Bitcoin 2024.csv', sep=';')\n",
    "df['date'] = pd.to_datetime(df['timeOpen'], format='ISO8601')\n",
    "\n",
    "df = df.sort_index(ascending=False).reset_index()\n",
    "df = df[['timeOpen','close']]\n",
    "\n",
    "input_values_scaled = scaler.fit_transform(df[['close']])\n",
    "\n",
    "input = input_values_scaled[:-1].flatten()\n",
    "input = torch.tensor(input, dtype=torch.float32)\n",
    "input_value = torch.tensor(input, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "label = input_values_scaled[-1]\n",
    "label_value = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "print(\"Bitcoin: Observed = 68526.1016, Predicted =\", model(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Features: tensor([[5.6149e-02, 5.1434e-02, 5.0057e-02, 6.6368e-02, 6.8768e-02, 9.0684e-02,\n",
      "         8.7900e-02, 8.5987e-02, 8.6410e-02, 6.1863e-02, 7.4144e-02, 8.0937e-02,\n",
      "         7.7630e-02, 9.1948e-02, 7.8817e-02, 6.9441e-02, 5.3579e-02, 5.2839e-02,\n",
      "         5.2067e-02, 3.9119e-02, 3.5037e-02, 3.4601e-02, 3.7656e-02, 4.3121e-02,\n",
      "         3.9867e-02, 4.7418e-02, 3.5604e-02, 3.6812e-02, 4.1805e-02, 3.3970e-02,\n",
      "         3.6002e-02, 4.3809e-02, 2.5233e-02, 2.8181e-02, 3.3250e-02, 3.6358e-02,\n",
      "         6.1740e-02, 5.4655e-02, 5.3748e-02, 4.3683e-02, 3.5349e-02, 4.4307e-02,\n",
      "         4.0669e-02, 4.1585e-02, 1.3249e-02, 4.4082e-02, 2.5466e-02, 2.8848e-02,\n",
      "         2.8268e-02, 1.5150e-02, 1.7004e-02, 1.6219e-02, 1.6557e-02, 0.0000e+00,\n",
      "         9.4189e-03, 2.5080e-02, 2.8900e-02, 2.5262e-02, 3.5997e-02, 6.6783e-02,\n",
      "         1.0223e-01, 9.9827e-02, 1.1616e-01, 1.1310e-01, 1.1167e-01, 1.0731e-01,\n",
      "         1.1601e-01, 1.0345e-01, 1.1094e-01, 1.1161e-01, 1.1396e-01, 1.1460e-01,\n",
      "         1.2577e-01, 1.1787e-01, 1.1238e-01, 9.9766e-02, 1.0879e-01, 1.0776e-01,\n",
      "         1.0523e-01, 1.1030e-01, 1.1460e-01, 1.0982e-01, 1.3243e-01, 1.0862e-01,\n",
      "         1.0782e-01, 1.0685e-01, 1.0470e-01, 9.8666e-02, 9.9862e-02, 9.7320e-02,\n",
      "         9.9754e-02, 9.6898e-02, 1.0342e-01, 8.4494e-02, 8.5547e-02, 8.8207e-02,\n",
      "         8.5198e-02, 8.7462e-02, 8.8247e-02, 8.6546e-02, 8.5603e-02, 9.4895e-02,\n",
      "         8.3974e-02, 8.4531e-02, 8.2350e-02, 8.1684e-02, 8.1678e-02, 8.4571e-02,\n",
      "         9.6767e-02, 9.2513e-02, 8.9763e-02, 8.9098e-02, 8.9479e-02, 8.6704e-02,\n",
      "         8.9322e-02, 8.4357e-02, 7.4587e-02, 3.2108e-02, 1.9285e-02, 2.0258e-02,\n",
      "         2.2205e-02, 2.0840e-02, 1.8912e-02, 2.7252e-02, 2.1637e-02, 1.9246e-02,\n",
      "         1.8428e-02, 2.0122e-02, 2.0465e-02, 5.4270e-02, 4.5301e-02, 1.6823e-02,\n",
      "         1.4096e-02, 1.5516e-02, 1.7617e-02, 1.4340e-02, 1.3664e-02, 1.3106e-02,\n",
      "         2.3260e-02, 1.6284e-02, 1.6076e-02, 1.4753e-02, 7.9190e-04, 1.4777e-02,\n",
      "         2.3012e-02, 2.9504e-02, 3.0944e-02, 3.0101e-02, 2.9390e-02, 3.3979e-02,\n",
      "         4.3505e-02, 4.1855e-02, 3.0087e-02, 3.0336e-02, 3.0333e-02, 2.3607e-02,\n",
      "         2.4475e-02, 2.2781e-02, 2.5606e-02, 3.9552e-02, 3.7262e-02, 3.8434e-02,\n",
      "         5.9615e-02, 5.0170e-02, 4.8068e-02, 5.5771e-02, 4.7775e-02, 5.8840e-02,\n",
      "         5.9304e-02, 5.8601e-02, 5.1273e-02, 4.7256e-02, 3.6461e-02, 3.4032e-02,\n",
      "         3.6233e-02, 3.6219e-02, 4.2432e-02, 7.0786e-02, 6.8623e-02, 6.6800e-02,\n",
      "         7.4963e-02, 9.5046e-02, 9.9955e-02, 1.0153e-01, 1.6601e-01, 1.8301e-01,\n",
      "         1.9555e-01, 1.8833e-01, 1.8318e-01, 1.8693e-01, 1.9629e-01, 1.9554e-01,\n",
      "         1.9899e-01, 2.1503e-01, 2.0462e-01, 2.0033e-01, 2.0763e-01, 2.0694e-01,\n",
      "         2.0669e-01, 2.1516e-01, 2.1958e-01, 2.4122e-01, 2.5416e-01, 2.5049e-01,\n",
      "         2.4875e-01, 2.3724e-01, 2.1712e-01, 2.6598e-01, 2.2999e-01, 2.3921e-01,\n",
      "         2.3898e-01, 2.5567e-01, 2.5756e-01, 2.2288e-01, 2.5663e-01, 2.5365e-01,\n",
      "         2.6263e-01, 2.6423e-01, 2.5761e-01, 2.5291e-01, 2.6494e-01, 2.6552e-01,\n",
      "         2.6248e-01, 2.8283e-01, 2.9925e-01, 3.0972e-01, 3.5146e-01, 3.9526e-01,\n",
      "         3.8829e-01, 3.7882e-01, 3.9705e-01, 3.8786e-01, 3.8898e-01, 3.3610e-01,\n",
      "         3.4041e-01, 3.7044e-01, 3.7322e-01, 3.5041e-01, 3.5688e-01, 3.3862e-01,\n",
      "         3.6487e-01, 3.5751e-01, 3.8632e-01, 3.9085e-01, 3.9353e-01, 3.8814e-01,\n",
      "         3.7306e-01, 3.8551e-01, 3.6272e-01, 3.8196e-01, 3.6496e-01, 3.5394e-01,\n",
      "         3.5514e-01, 3.5740e-01, 3.9706e-01, 4.1355e-01, 3.6956e-01, 3.9733e-01,\n",
      "         3.9697e-01, 3.9335e-01, 3.9239e-01, 4.5551e-01, 4.3819e-01, 4.4837e-01,\n",
      "         4.4296e-01, 3.6966e-01, 3.6944e-01, 3.4762e-01, 3.6255e-01, 3.7595e-01,\n",
      "         3.6736e-01, 3.3648e-01, 3.4391e-01, 3.4490e-01, 3.4240e-01, 2.9990e-01,\n",
      "         3.0695e-01, 3.1178e-01, 3.0879e-01, 3.4805e-01, 3.5437e-01, 3.5261e-01,\n",
      "         3.7873e-01, 3.7173e-01, 3.6402e-01, 3.7430e-01, 3.7660e-01, 3.7256e-01,\n",
      "         3.6404e-01, 3.6561e-01, 3.7449e-01, 4.0021e-01, 4.2071e-01, 4.5920e-01,\n",
      "         4.7221e-01, 4.8311e-01, 5.1781e-01, 5.1331e-01, 5.5677e-01, 5.5910e-01,\n",
      "         5.6372e-01, 5.5336e-01, 5.6294e-01, 5.5578e-01, 5.6632e-01, 5.5703e-01,\n",
      "         5.4589e-01, 5.3394e-01, 5.5144e-01, 5.5482e-01, 6.1298e-01, 6.6642e-01,\n",
      "         7.7942e-01, 7.5218e-01, 7.7808e-01, 7.6952e-01, 7.9324e-01, 9.0089e-01,\n",
      "         8.0645e-01, 8.5453e-01, 8.7160e-01, 9.0026e-01, 9.0441e-01, 9.1527e-01,\n",
      "         9.7999e-01, 9.6659e-01, 1.0000e+00, 9.6483e-01, 9.2327e-01, 8.3802e-01,\n",
      "         9.0215e-01, 8.8459e-01, 7.6708e-01, 8.9220e-01, 8.4170e-01, 8.0598e-01,\n",
      "         8.1189e-01, 8.7803e-01, 9.3485e-01, 9.3545e-01, 9.2435e-01, 9.5124e-01,\n",
      "         9.3347e-01, 9.2831e-01, 9.6351e-01, 9.2949e-01, 8.4077e-01, 8.5190e-01,\n",
      "         9.0461e-01, 8.9062e-01, 9.1269e-01, 9.2241e-01, 9.6972e-01, 9.1775e-01,\n",
      "         9.4796e-01, 9.3697e-01, 8.7724e-01, 8.0688e-01, 8.4685e-01, 7.9863e-01,\n",
      "         8.0668e-01, 7.5381e-01, 8.0044e-01, 8.0734e-01, 8.3133e-01, 8.2992e-01,\n",
      "         8.6977e-01, 8.6079e-01, 8.1637e-01, 8.2064e-01, 8.0550e-01, 7.9849e-01,\n",
      "         7.9211e-01, 8.0729e-01, 7.4047e-01, 6.9079e-01, 7.0892e-01, 7.8745e-01,\n",
      "         8.0834e-01, 8.1125e-01, 7.9312e-01, 7.7588e-01, 7.5196e-01, 7.9079e-01,\n",
      "         7.4372e-01, 7.4374e-01, 7.5739e-01, 7.8769e-01, 7.5957e-01, 8.5788e-01,\n",
      "         8.3628e-01, 8.7423e-01, 8.7192e-01, 8.5810e-01, 9.6590e-01, 9.3855e-01,\n",
      "         9.1740e-01, 8.9253e-01]])\n",
      "Batch Targets: tensor([0.9050])\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(input_value, label_value)\n",
    "dataloader = DataLoader(dataset) \n",
    "\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(\"Batch Features:\", inputs)\n",
    "    print(\"Batch Targets:\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin: Observed = 0.9050, Predicted = tensor(-0.2471, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Bitcoin: Observed = 0.9050, Predicted =\", model(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /Users/maulanashendi/self-project/model-from-scratch/LSTM/uploaded/lightning_logs\n",
      "\n",
      "  | Name         | Type | Params | Mode\n",
      "---------------------------------------------\n",
      "  | other params | n/a  | 12     | n/a \n",
      "---------------------------------------------\n",
      "12        Trainable params\n",
      "0         Non-trainable params\n",
      "12        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/Users/maulanashendi/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/maulanashendi/anaconda3/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c0e95aa06049b782856378ccfdb68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=200)\n",
    "trainer.fit(model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin: Observed = 0.9050, Predicted = tensor(0.8908, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Bitcoin: Observed = 0.9050, Predicted =\", model(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at /Users/maulanashendi/self-project/model-from-scratch/LSTM/uploaded/lightning_logs/version_0/checkpoints/epoch=199-step=200.ckpt\n",
      "/Users/maulanashendi/anaconda3/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:360: The dirpath has changed from '/Users/maulanashendi/self-project/model-from-scratch/LSTM/uploaded/lightning_logs/version_0/checkpoints' to '/Users/maulanashendi/self-project/model-from-scratch/LSTM/uploaded/lightning_logs/version_2/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "\n",
      "  | Name         | Type | Params | Mode\n",
      "---------------------------------------------\n",
      "  | other params | n/a  | 12     | n/a \n",
      "---------------------------------------------\n",
      "12        Trainable params\n",
      "0         Non-trainable params\n",
      "12        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at /Users/maulanashendi/self-project/model-from-scratch/LSTM/uploaded/lightning_logs/version_0/checkpoints/epoch=199-step=200.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95eae04eca264efa97a9a139fa9abd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    }
   ],
   "source": [
    "path_to_best_chackpoint = trainer.checkpoint_callback.best_model_path\n",
    "trainer = L.Trainer(max_epochs=400)\n",
    "trainer.fit(model, train_dataloaders=dataloader, ckpt_path=path_to_best_chackpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin: Observed = 0.9050, Predicted = tensor(0.9050, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Bitcoin: Observed = 0.9050, Predicted =\", model(input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
